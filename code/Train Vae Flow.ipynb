{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dff1c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path  = '/data/reference_split_64par_mel.th'\n",
    "data_file = 'reference_split_64par_mel.th'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3116adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib \n",
    "import os \n",
    "import time \n",
    "import numpy as np \n",
    "import torch\n",
    "from torch.jit import Error \n",
    "import torch.nn as nn   \n",
    "import torch.optim as optim\n",
    "from torch.optim import optimizer \n",
    "\n",
    "# Internal imports \n",
    "from utils.data import CompSynthesizerDataset\n",
    "from utils.data import load_dataset, get_external_sounds \n",
    "from models.vae.ae import AE, RegressionAE, DisentanglingAE\n",
    "from models.vae.vae import VAE \n",
    "from models.vae.vae_flow import VAEFlow \n",
    "from models.loss import multinomial_loss, multinomial_mse_loss \n",
    "from models.basic import GatedMLP, GatedCNN, construct_encoder_decoder, construct_flow, construct_disentangle, construct_regressor \n",
    "from evaluate  import (evaluate_model, evaluate_params, evaluate_synthesis,\\\n",
    "            evaluate_projection, evaluate_reconstruction, evaluate_latent_space,\\\n",
    "            evaluate_meta_parameters, evaluate_semantic_parameters,\\\n",
    "            evaluate_latent_neighborhood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4447258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constants: \n",
    "    DATASET_PATH = '/data/reference_split_64par_mel.th'\n",
    "    TEST_SOUNDS_PATH = '' \n",
    "    OUTPUTS = 'outputs' \n",
    "    DATASET = '32par' \n",
    "    DATA_TYPE = 'mel' \n",
    "    TRAIN_TYPE = 'fixed' \n",
    "    N_WORKERS = 0 \n",
    "    MODEL = 'vae' \n",
    "    LOSS = 'mse' \n",
    "    REC_LOSS = 'mse' \n",
    "    N_CLASSES = 61 \n",
    "    N_HIDDEN = 1024 \n",
    "    N_LAYERS = 4 \n",
    "    CHANNELS = 64 \n",
    "    KERNEL = 5 \n",
    "    DILATION = 3 \n",
    "    LAYERS = 'vae_flow' \n",
    "    ENCODER_DIMS = 64 \n",
    "    LATENT_DIMS = 0 \n",
    "    WARM_LATENT = 50 \n",
    "    START_REGRESS = 100 \n",
    "    WARM_REGRESS = 100 \n",
    "    BETA_FACTOR = 1 \n",
    "    REF_MODEL = '' \n",
    "    FLOW = 'iaf' # Type of flow to use \n",
    "    FLOW_LENGTH = 16 # Number of flow transforms \n",
    "    REGRESSOR = 'mlp' # Type of regressor\n",
    "    REG_LAYERS = 3  # Number of regression layers\n",
    "    REG_HIDDENS = 256 # Number of units in regressor\n",
    "    REG_FLOW = \"maf\" # Type of flow in regressor \n",
    "    REG_FACTOR = 1e3 # Regression loss weight \n",
    "    K_RUN = 0 # ID of Runs (k-folds) \n",
    "    EARLY_STOP = 60 # Early stopping \n",
    "    PLOT_INTERVAL = 100 # Interval of plotting frequency \n",
    "    BATCH_SIZE = 64 \n",
    "    EPOCHS = 200 \n",
    "    EVAL = 100 # frequency of full evaluation \n",
    "    LR = 2e-4 # The learning rate\n",
    "    SEMANTIC_DIM = -1 # Using semantic dimension \n",
    "    DIS_LAYERS = 8 # Number of disentangling layers \n",
    "    DISENTANGLING = \"density\" # Disentangling approach \n",
    "    START_DISENTANGLE = 100 # Epoch to start disentangling \n",
    "    WARM_DISENTANGLE = 25 # Warmup disentanglement \n",
    "    BATCH_EVALS = 16 # Number of batch to evaluate \n",
    "    BATCH_OUT = 3 # Number of batch to synthesize) \n",
    "    TIME_LIMIT = 0 # Maximum time to train in minutes \n",
    "    DEVICE = 'cpu' # Device (GPU Or CPU)\n",
    "    SYNTHESIZE = False \n",
    "    VOCAL_SOUNDS_PATH = ''\n",
    "    MODEL_PATH = '/models'\n",
    "    INPUT_SIZE = 10 # This is the  input size to the encoder its needs to be defined by the user\n",
    "    OUTPUT_SIZE = 10 # TODO: this value needs to be defined by the user\n",
    "    OUTPUT = 'outputs' # path to saved models\n",
    "    PLOT = '' # \n",
    "    MODEL_NAME = 'vae_with_flow'\n",
    "    DATASET_NAMES = {'toy': 'toy', '32par':'32par', '64par':'64par', '64par_aug':'64par_aug', '128par':'128par'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c69598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossTypes:\n",
    "    MSE = \"mse\" \n",
    "    L1 = \"l1\" \n",
    "    MULTINOMIAL = \"multinomial\" \n",
    "    MULTINOMIAL_MSE = \"multi_mse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c9d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_checkpoint_dirs(): \n",
    "    if not os.path.exists('{0}'.format(Constants.OUTPUTS)):\n",
    "        print('***Creating Output directories***')\n",
    "        os.makedirs('{0}'.format(Constants.OUTPUTS)) \n",
    "        os.makedirs('{0}/audio'.format(Constants.OUTPUTS)) \n",
    "        os.makedirs('{0}/images'.format(Constants.OUTPUTS)) \n",
    "        os.makedirs('{0}/models'.format(Constants.OUTPUTS))\n",
    "        print('***Directories created***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14d025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, data, loss, latent_dims):\n",
    "    model_name = '{0}_{1}_{2}_{3}'.format(model, data, loss, latent_dims)\n",
    "    model_name += '_' + Constants.FLOW\n",
    "    if(not (Constants.MODEL in ['mlp', 'gated_mlp', 'cnn', 'gated_cnn', 'res_cnn'])):\n",
    "        model_name += '_' + Constants.LAYERS\n",
    "    model_name += '_' + Constants.FLOW\n",
    "    if(Constants.SEMANTIC_DIM > -1):\n",
    "        model_name += '_' + str(Constants.SEMANTIC_DIM) + '_' + Constants.DISENTANGLING \n",
    "    if(Constants.K_RUN > 0):\n",
    "        model_name += '_' + str(Constants.K_RUN) \n",
    "    base_dir = '{0}'.format(Constants.OUTPUTS) \n",
    "    base_img = '{0}/images/{1}'.format(Constants.OUTPUTS, model_name) \n",
    "    base_audio = '{0}/audio/{1}'.format(Constants.OUTPUTS, model_name)\n",
    "    return torch.save(model.state_dict(), Constants.MODEL_PATH + '/' + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bb25bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name, path, data, **kwargs):\n",
    "    if(dataset_name in ['toy'], ['32par'], ['64par'], ['64par_aug'], ['128par']):\n",
    "        params = {'32par': '32contparams.txt', '64par': '64contparams.txt', '64par_aug': '64contparams.txt',\n",
    "        '128par': '128contparams.txt'}\n",
    "        with open('synth/params/' + params[dataset_name]) as f: \n",
    "            use_params = [line.strip() for line in f] \n",
    "        dset_train = CompSynthesizerDataset(path + '/' + dataset_name, use_params, data=data, **kwargs) \n",
    "        dset_valid = copy.deepcopy(dset_train).switch_set('valid')\n",
    "        dset_test = copy.deepcopy(dset_train).switch_set('test') \n",
    "        dset_train = dset_train.switch_set('train')\n",
    "    else:\n",
    "        raise Exception('Wrong dataset name!!')\n",
    "    input_size = dset_train.input_size \n",
    "    output_size = dset_train.output_size \n",
    "    train_loader = DataLoader(dset_train, batch_size=Constants.BATCH_SIZE, shuffle=True, num_workers=Constants.N_WORKERS, pin_memory=False,\\\n",
    "        **kwargs)\n",
    "    valid_loader = DataLoader(dset_valid, batch_size=Constants.BATCH_SIZE, shuffle= (Constants.TRAIN_TYPE == 'random'),\\\n",
    "        num_workers=Constants.N_WORKERS, pin_memory=False, **kwargs)\n",
    "    test_loader = DataLoader(dset_test, batch_size=Constants.BATCH_SIZE, shuffle=(Constants.TRAIN_TYPE == 'random'),\n",
    "    n_workers=Constants.N_WORKERS, pin_memory=False, **kwargs)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "    \n",
    "\n",
    "\n",
    "def get_dataloaders():\n",
    "    \n",
    "    dataset_name = Constants.DATASET_NAMES['64par']\n",
    "    path = dataset_path\n",
    "    train_loader, valid_loader, test_loader = load_data(dataset_name, path=path, data= dataset_path + '/' + data_file)\n",
    "    data = torch.load(ref_split) \n",
    "    train_loader, valid_loader, test_loader = data[0], data[1], data[2] \n",
    "    return train_loader, valid_loader, test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc99c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_data(): \n",
    "    _, _, test_loader = get_dataloaders() \n",
    "    fixed_data, fixed_params, fixed_meta, fixed_audio = next(iter(test_loader)) \n",
    "    fixed_data, fixed_params = fixed_data.to(Constants.DEVICE), fixed_params.to(Constants.DEVICE)\n",
    "    fixed_batch = (fixed_data, fixed_params, fixed_meta, fixed_audio)\n",
    "    return fixed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77124168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_dims():\n",
    "    latent_dims = 0 \n",
    "    train_loader, _, _ = get_dataloaders() \n",
    "    if Constants.LATENT_DIMS == 0: \n",
    "        latent_dims = train_loader.dataset.ouput_size\n",
    "    return latent_dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "753c8773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss_type=\"\"):\n",
    "    loss = None \n",
    "    if loss_type == \"mse\":\n",
    "        loss = nn.MSELoss(reduction=\"sum\").to(Constants.DEVICE) \n",
    "    elif loss_type == \"l1\":\n",
    "        loss = nn.SmoothL1Loss(reduction=\"sum\").to(Constants.DEVICE) \n",
    "    elif loss_type == \"multinomial\":\n",
    "        loss = multinomial_loss \n",
    "    elif loss_type == \"multi_mse\":\n",
    "        loss = multinomial_mse_loss \n",
    "    else: \n",
    "        raise Exception(\"Unknown reconstruction loss \" + loss_type)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c82da732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_and_output_size(error_type=None):\n",
    "    train_data_loader, _, _ = get_dataloaders()\n",
    "    input_size = train_data_loader.dataset.input_size \n",
    "    output_size = train_data_loader.dataset.output_size\n",
    "    if error_type in ['multinomial']: \n",
    "        output_size *= Constants.N_CLASSES \n",
    "    elif error_type in ['multinomial_mse']: \n",
    "        output_size *=(Constants.N_CLASSES + 1) \n",
    "    return input_size, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de96aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_vae_with_flow_model():\n",
    "    latent_dims = get_latent_dims()\n",
    "    flow = Constants.FLOW \n",
    "    flow_length = Constants.FLOW_LENGTH \n",
    "    rec_loss = get_loss(loss_type=LossTypes.MSE)\n",
    "    input_size, output_size = get_input_and_output_size()\n",
    "    channels = Constants.CHANNELS \n",
    "    n_layers = Constants.N_LAYERS\n",
    "    hidden_size = Constants.N_HIDDEN \n",
    "    type_mod = Constants.LAYERS\n",
    "    encoder_dims = Constants.ENCODER_DIMS\n",
    "    regressor = Constants.REGRESSOR\n",
    "    reg_hiddens = Constants.REG_HIDDENS \n",
    "    reg_flow = Constants.REG_FLOW \n",
    "    reg_layers = Constants.REG_LAYERS\n",
    "    semantic_dim = Constants.SEMANTIC_DIM\n",
    "    disentangling = Constants.DISENTANGLING \n",
    "    dis_layers = Constants.DIS_LAYERS\n",
    "\n",
    "    encoder, decoder = construct_encoder_decoder(Constants.INPUT_SIZE, Constants.ENCODER_DIMS,\\\n",
    "        latent_dims, channels = channels, n_layers=n_layers, hidden_size=hidden_size, n_mlp= n_layers//2, type_mod=type_mod)\n",
    "    flow, blocks = construct_flow(latent_dims, flow_type=flow, flow_length=flow_length, amortization='input') \n",
    "\n",
    "    model = VAEFlow(encoder, decoder, input_size, encoder_dims, latent_dims)\n",
    "    # construct specific regressor\n",
    "    regression_model = construct_regressor(latent_dims, output_size, model=regressor,\\\n",
    "        hidden_dims=reg_hiddens, n_layers=reg_layers, flow_type=reg_flow)\n",
    "    if(semantic_dim == -1):\n",
    "        model = RegressionAE(model, latent_dims, output_size, rec_loss, regressor=regression_model,\\\n",
    "            regressor_name=regressor)\n",
    "    else:\n",
    "        # Construct disentangling flow\n",
    "        disentangling = construct_disentangle(latent_dims, model=disentangling, semantic_dim=semantic_dim,\\\n",
    "            n_layers=dis_layers, flow_type=reg_flow)\n",
    "        model = DisentanglingAE(model, latent_dims, output_size, rec_loss, regressor=regression_model,\\\n",
    "            regressor_name=regressor, disentangling=disentangling, semantic_dim=semantic_dim)\n",
    "    model = model.to(Constants.DEVICE) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03bb84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adam_optimizer_and_scheduler(model):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=Constants.LR)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.5, patience=20, verbose=True, threshold=1e-7)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e69b6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_evaluation(model, losses, test_loader, args): \n",
    "    plot = Constants.PLOT \n",
    "    plot = 'final' \n",
    "    model_name = Constants.MODEL_NAME\n",
    "    base_img = None \n",
    "    base_dir = None \n",
    "    base_audio = None \n",
    "    base_model_name = None \n",
    "    base_model = Constants.OUTPUT + '/models/' + model_name  \n",
    "    vocal_sounds = None\n",
    "    device = set_device(device_type=\"cpu\")\n",
    "    print('[Reload best performing model]') \n",
    "    model = torch.load(Constants.OUTPUT + '/models/' + model_name + '.model') \n",
    "    model = model.to(device)\n",
    "    print('[Performing final evaluation]') \n",
    "    # Memory saver \n",
    "    with torch.no_grad(): \n",
    "        # Perform parameters evaluation \n",
    "        evaluate_params(model, test_loader, args, losses=losses)\n",
    "        # Synthesis engine on (GPU) \n",
    "        if(torch.device() == \"gpu\" and Constants.SYNTHESIZE):\n",
    "            # Importh synthesis \n",
    "            from synth.synthesize import create_synth \n",
    "            print('[Synthesis evaluation]') \n",
    "            engine, generator, param_defaults, rev_idx = create_synth(Constants.DATASET) \n",
    "        # Perform reconstruction evaluation\n",
    "        evaluate_reconstruction(model, test_loader, args, train=False) \n",
    "        # Evaluate latent space \n",
    "        args = evaluate_latent_space(model, test_loader, args, train=False)\n",
    "        # Perform meta-parameter analysis \n",
    "        evaluate_meta_parameters(model, test_loader, args, train=False) \n",
    "        # Perform latent neighborhood analysis\n",
    "        evaluate_latent_neighborhood(model, test_loader, args, train=False)\n",
    "\n",
    "        if (Constants.SYNTHESIZE): \n",
    "            # Evaluate synthetizer output \n",
    "            evaluate_synthesis(model, test_loader, args, train=False) \n",
    "            print('[Load set of testing sound (outside Diva)]') \n",
    "            test_sounds = get_external_sounds(vocal_sounds, test_loader.dataset, args)\n",
    "            # Evaluate projection \n",
    "            evaluate_projection(model, test_sounds, args, train=False, type_val='vocal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47e2be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(with_final_evaluation=False):\n",
    "    epochs = Constants.EPOCHS\n",
    "    losses = torch.zeros(epochs, 3) \n",
    "    beta_factor = Constants.BETA_FACTOR\n",
    "    beta = 0 \n",
    "    warm_latent = Constants.WARM_LATENT\n",
    "    gamma = 0\n",
    "    reg_factor = Constants.REG_FACTOR\n",
    "    warm_regress = Constants.WARM_REGRESS\n",
    "    start_regress = Constants.START_REGRESS\n",
    "    delta = 0 \n",
    "    start_disentangle = Constants.START_DISENTANGLE\n",
    "    warm_disentangle = Constants.WARM_DISENTANGLE\n",
    "    early_stop = Constants.EARLY_STOP\n",
    "    regressor = Constants.REGRESSOR\n",
    "    plot_interval = Constants.PLOT_INTERVAL\n",
    "    plot = Constants.PLOT\n",
    "    fixed_batch = get_fixed_data()\n",
    "    model = define_vae_with_flow_model()\n",
    "    model_name = 'vae_with_flow'\n",
    "    base_dir = '{0}'.format(Constants.OUTPUTS) \n",
    "    base_img = '{0}/images/{1}'.format(Constants.OUTPUTS, model_name) \n",
    "    base_audio = '{0}/audio/{1}'.format(Constants.OUTPUTS, model_name)\n",
    "    train_loader, valid_loader, test_loader = get_dataloaders()\n",
    "    loss = get_loss(loss_type=LossTypes.MSE)\n",
    "    adam_optimizer, scheduler = get_adam_optimizer_and_scheduler(model)\n",
    "    if(epochs == 0):\n",
    "        losses = torch.zeros(200, 3) \n",
    "    best_loss = np.inf \n",
    "    print('[Starting Training]') \n",
    "    for i in range(epochs):\n",
    "        if(start_regress == 0):\n",
    "            from pympler import muppy, summary \n",
    "            all_objects = muppy.get_objects() \n",
    "            sum1 = summary.summarize(all_objects) \n",
    "            # Prints out a summary of the large objects \n",
    "            print('******* Summary at the beginning of epoch *******')\n",
    "            summary.print_(sum1) \n",
    "        # set warm-up values \n",
    "        beta = beta_factor * (float(i) / float(max(warm_latent, i)))\n",
    "        if( i >= start_regress):\n",
    "            gamma = ((float(i - start_regress) * reg_factor) / float(max(warm_regress, i - start_regress)))\n",
    "            if(regressor != 'mlp'):\n",
    "                gamma *= 1e-1\n",
    "        else: \n",
    "            gamma = 0 \n",
    "        if(i >= start_disentangle):\n",
    "            delta = ((float(i - start_disentangle)) / float(max(warm_disentangle, i - start_disentangle)))\n",
    "        else: \n",
    "            delta = 0 \n",
    "        print('%.3f - % .3f' % (beta, gamma))\n",
    "        # Perform one epoch of train \n",
    "        losses[i, 0] = model.train_epoch(train_loader, loss, adam_optimizer, args)\n",
    "        # Perform validation \n",
    "        losses[i, 1] = model.eval_epoch(valid_loader, loss, optimizer, args)\n",
    "        # Learning rate scheduling\n",
    "        if( i>= start_regress):\n",
    "            scheduler.step(losses[i, 1]) \n",
    "        # Perform test evaluation \n",
    "        losses[i, 2] = model.eval_epoch(test_loader, loss, args) \n",
    "        if (start_regress == 1000): \n",
    "            losses[i, 1] = losses[i, 0] \n",
    "            losses[i, 2] = losses[i, 0]\n",
    "        # Model saving \n",
    "        if(losses[i, 1] < best_loss): \n",
    "            # Save model \n",
    "            best_loss = losses[i, 1] \n",
    "            torch.save(model, Constants.OUTPUTS + '/models/' + model_name + '.model')\n",
    "            early = 0 \n",
    "        # Check for early stopping \n",
    "        elif(early_stop > 0 and i > start_regress): \n",
    "            early += 1 \n",
    "            if(early > early_stop):\n",
    "                print('[Model stopped early]') \n",
    "                break  \n",
    "        # Periodic evaluation (or debug model) \n",
    "        if((i + 1) % plot_interval == 0 or (epochs == 1)):\n",
    "            plot = 'train' \n",
    "            with torch.no_grad(): \n",
    "                model.eval() \n",
    "                evaluate_model(model, fixed_batch, test_loader, args, train=True, name=base_img + '_batch_' + str(i))\n",
    "        print('Epoch ' + str(i)) \n",
    "        print(losses[i]) \n",
    "        torch.cuda.empty_cache()\n",
    "        if(with_final_evaluation):\n",
    "            make_final_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35424cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    #set_device(device_type=\"cpu\") \n",
    "    make_checkpoint_dirs()\n",
    "    #check_parameters()\n",
    "    train_model(with_final_evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aeb1a60f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-85ba4973bfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-55d6f0d18464>\u001b[0m in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmake_checkpoint_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#check_parameters()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final_evaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-92f20a5479aa>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(with_final_evaluation)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplot_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLOT_INTERVAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLOT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mfixed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fixed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_vae_with_flow_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'vae_with_flow'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-50ac9fd248e0>\u001b[0m in \u001b[0;36mget_fixed_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_fixed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfixed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfixed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfixed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfixed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-8565a2890ad7>\u001b[0m in \u001b[0;36mget_dataloaders\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_NAMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'64par'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-8565a2890ad7>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dataset_name, path, data, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'synth/params/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0muse_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompSynthesizerDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdset_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/gigs/flow_synthesizer/code/utils/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, datadir, use_params, transform, data, splits, shuffle_files)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpecData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/gigs/flow_synthesizer/code/utils/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, datadir, spectral_files, transform, data_type, stats, set_type)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Compute mean and std of dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# entire set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#train, test, valid sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Work/gigs/flow_synthesizer/code/utils/data.py\u001b[0m in \u001b[0;36mcompute_normalization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd95103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
